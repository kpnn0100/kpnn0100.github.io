import type { ProgrammingItem } from "../types";

const item: ProgrammingItem = {
  id: "6",
  title:
    "True Position: Spatial Audio Simulation via Room Modelling in a VST3 Plugin",
  authors: ["Nam Doan (kpnn)"],
  year: "2023",
  conference: "Open Source · Audio DSP",
  abstract:
    "True Position is an open-source VST3 plugin that converts a mono input into a convincing stereo spatial image. It places a virtual sound source inside a configurable rectangular room and simulates direct-path propagation, inter-aural time difference, acoustic head-shadow filtering, early reflections from six walls using the image-source method, and a diffuse reverb tail generated by a feedback delay network. All processing parameters — position, room dimensions, mix, decay, and EQ — are smoothly interpolated at sample rate to avoid audible artefacts during automation.",
  tags: [
    "Audio DSP",
    "C++",
    "VST3",
    "Spatial Audio",
    "JUCE",
    "Real-Time",
    "Open Source",
  ],
  link: "https://github.com/kpnn0100/TruePosition",
  sections: [
    {
      num: "1",
      heading: "Introduction",
      content: [
        {
          type: "paragraph",
          text: "When we listen to sound in a physical room, our brain reconstructs the position of the source from a rich set of cues: the tiny time difference between the two ears (inter-aural time difference, or ITD), the frequency-dependent level difference caused by the head blocking high frequencies on the far side (acoustic shadow), the pattern of early wall reflections, and the diffuse reverb tail that follows. True Position recreates all four cues in software, turning a single mono channel into a spatialised stereo output that places the listener inside a virtual room.",
        },
        {
          type: "figure",
          src: "/programming/true-position/visual.png",
          alt: "True Position VST3 plugin user interface",
          caption:
            "Figure 1. The True Position interface. The 3D room visualisation lets users drag the sound source; knobs control dry/wet, reverb, decay, and EQ.",
          figNum: 1,
        },
        {
          type: "paragraph",
          text: "The plugin is built on two pillars: a custom DSP library called Gyrus Space DSP, which provides modular signal-processing blocks with automatic property interpolation, and the JUCE framework for the plugin host interface and GUI. This article walks through every layer of the signal path so that a reader with basic DSP knowledge can understand exactly what happens to each audio sample.",
        },
      ],
    },
    {
      num: "2",
      heading: "Background — How We Localise Sound",
      content: [
        {
          type: "paragraph",
          text: "Human ears are spaced roughly 20 cm apart. A sound arriving from the right reaches the right ear before the left. At 343 m/s (the speed of sound in air), a full 20 cm offset produces about 0.58 ms of delay — small, but the auditory system is extraordinarily sensitive to it. This is inter-aural time difference (ITD).",
        },
        {
          type: "paragraph",
          text: "Additionally, the head itself is an obstacle. High-frequency sounds (wavelengths shorter than the head diameter) are partially blocked, creating a level difference and a spectral tilt on the far ear. This is the acoustic shadow effect. Below roughly 500 Hz the head is nearly transparent; above it, attenuation can exceed 10 dB.",
        },
        {
          type: "paragraph",
          text: "After the direct sound arrives, reflections from walls, ceiling, and floor arrive within about 50 ms — the early reflections. These provide the brain with cues about the size and shape of the room. Later still, the accumulated bounces blur into a diffuse reverb tail whose decay time depends on the room's absorption properties.",
        },
      ],
    },
    {
      num: "3",
      heading: "Architecture — The Gyrus Space DSP Library",
      content: [
        {
          type: "paragraph",
          text: "All signal processing in True Position is built on a modular library structured around a single abstract base class: SignalProcessor. Every processor — delay lines, gain stages, filters, the reverb engine, and the spatial positioners — inherits from this class. SignalProcessor provides three critical features: (1) a virtual process(double in) method that each subclass implements, (2) an automatic property interpolation system that smoothly transitions parameter changes over one buffer period, and (3) a hierarchical parent–child relationship that propagates sample-rate and buffer-size changes.",
        },
        {
          type: "code",
          language: "cpp",
          caption:
            "Listing 1. The SignalProcessor base class (simplified). Every DSP module inherits from this and implements process().",
          code: `class SignalProcessor {
protected:
    std::vector<Property> mPropertyList;
    static double mSampleRate;
    static int mBufferSize;

    virtual double process(double in) = 0;
    void setProperty(int id, double value);
    double getProperty(int id);

public:
    double out(double in);          // calls process() + smooth update
    static void setSampleRate(double sr);
    static void setBufferSize(double bs);
    void setSmoothEnable(bool enable);
};`,
        },
        {
          type: "paragraph",
          text: "On top of SignalProcessor sit two container classes. Block chains multiple processors either in series (output of one feeds the next) or in parallel (all receive the same input and their outputs are summed). FeedbackBlock implements a feedback loop topology: the output of a forward processor is mixed back into the input through a feedback processor — this is the fundamental building block of the reverb engine.",
        },
        {
          type: "code",
          language: "cpp",
          caption:
            "Listing 2. FeedbackBlock topology — the basis of the reverb feedback delay network.",
          code: `/*                             ------------------
*                 ___          |                 |
input----------->| + |---->----|mForwardProcessor|-------> output
                  ---          |_________________|    |
                   ^                                  |
                   |          ---------------------   |
                   |---<------| mFeedbackProcessor |--|
                              |____________________|
*/`,
        },
      ],
    },
    {
      num: "4",
      heading: "Direct Path — The Positioner",
      content: [
        {
          type: "paragraph",
          text: "The Positioner class models the propagation of sound from a source coordinate to a single destination coordinate. It computes two things: a delay (distance ÷ speed of sound, converted to samples) and a gain (inverse-distance law: gain = 1/distance). The delay is applied by a fractional delay line that uses linear interpolation between adjacent samples to achieve sub-sample accuracy, which is essential for smooth Doppler-effect pitch shifts when the source moves.",
        },
        {
          type: "code",
          language: "cpp",
          caption:
            "Listing 3. The Positioner computes delay and gain from 3D coordinates.",
          code: `void Positioner::updateDelaySample() {
    double distance = mSource.distanceTo(mDestination);
    double distanceToDelay = distance / SPEED_OF_SOUND * mSampleRate;
    mCurrentDistance = distance;
    mDelayFilter.setDelay(distanceToDelay);
}

void Positioner::updateGain() {
    if (mCurrentDistance == 0.0)
        mGainFilter.setGain(1.0);
    else
        mGainFilter.setGain(
            STANDARD_DISTANCE / (mCurrentDistance + offsetDistance)
        );
}`,
        },
        {
          type: "paragraph",
          text: "Because the delay filter has smooth interpolation enabled, moving the source coordinate doesn't produce a click — instead, the delay ramps continuously, which naturally creates the Doppler pitch shift that a real moving source would produce.",
        },
      ],
    },
    {
      num: "5",
      heading: "Stereo Imaging — The PositionSimulator",
      content: [
        {
          type: "paragraph",
          text: "A single Positioner models one ear. The PositionSimulator wraps two Positioners, offset by ±10 cm along the X axis (the inter-aural axis) to represent the left and right ears. The same source coordinate feeds both, but because the ear positions differ, each Positioner computes a slightly different delay and gain — this creates ITD and inter-aural level difference (ILD) automatically.",
        },
        {
          type: "code",
          language: "cpp",
          caption:
            "Listing 4. The ear offset that creates ITD. EAR_DISTANCE = 0.20 m.",
          code: `void PositionSimulator::setDestination(Coordinate destination) {
    mDestination = destination;
    for (int i = 0; i < CHANNEL_COUNT; i++)
        mPositioner[i].setDestination(
            destination
            - Coordinate(EAR_DISTANCE / 2, 0, 0)
            + Coordinate(EAR_DISTANCE, 0, 0) * i
        );
    updateGain();
}`,
        },
        {
          type: "paragraph",
          text: "The PositionSimulator also models the acoustic shadow. It computes the angle between the source and each ear on the XZ plane, then maps that angle to a ratio between 0.5 and 1.0. The near ear (facing the source) gets ratio ≈ 1.0 (full signal). The far ear gets a lower ratio, and the 'missing' energy is routed through a 500 Hz low-pass filter before being added back. This mimics the head blocking high frequencies while passing low frequencies around.",
        },
        {
          type: "code",
          language: "cpp",
          caption:
            "Listing 5. Acoustic shadow: the far ear receives more low-pass filtered signal.",
          code: `// ratio ≈ 1.0 for near ear, ≈ 0.5 for far ear
mParallelGainForLowpass[i].setGain(ratio);        // direct path
mRatioGainForLowpass[i].setGain((1 - ratio) * 2); // through LP filter

// Signal chain per ear:
//   input -> [direct * ratio] + [lowpass * (1-ratio)*2]`,
        },
      ],
    },
    {
      num: "6",
      heading: "Early Reflections — The Image-Source Method",
      content: [
        {
          type: "paragraph",
          text: "When sound hits a wall, it bounces. The simplest model for computing reflection paths is the image-source method: for each wall, you create a mirror image of the source on the other side. The distance from the listener to each image source equals the path length of the corresponding reflection. True Position applies this in 3D for all six faces of the room (four walls, floor, ceiling).",
        },
        {
          type: "paragraph",
          text: "The RoomSimulation class generates a list of reflection indices based on a configurable depth parameter. At depth 1, it considers first-order reflections only (sound bouncing off one wall before reaching the listener). For each (x, y, z) index triplet, it computes whether the coordinate was flipped (odd index = reflected off that axis) or shifted (even index = direct through that axis), producing the mirror-image source coordinate.",
        },
        {
          type: "code",
          language: "cpp",
          caption:
            "Listing 6. Mirror-image coordinate calculation for wall reflections.",
          code: `void RoomSimulation::updateSingleReflector(int x, int y, int z, int idx) {
    Coordinate destination = mDestination;
    int coor[] = { x, y, z };
    for (int i = 0; i < 3; i++) {
        if (coor[i] % 2 == 0) {
            // Even: shift by room multiples (direct path through axis)
            destination.set(i,
                destination.get(i) + coor[i] * mRoomSize.get(i));
        } else {
            // Odd: flip across the wall (reflection)
            double flip = mRoomSize.get(i) - destination.get(i);
            double shifted = flip + coor[i] * mRoomSize.get(i);
            destination.set(i, mSource.get(i) - (shifted - mSource.get(i)));
        }
    }
    mBounceSource[idx].setDestination(destination);
}`,
        },
        {
          type: "paragraph",
          text: "Each mirror-image source is processed by its own PositionSimulator, so every reflection gets proper ITD, ILD, and distance-based attenuation for free. The result is a convincing early-reflection pattern that changes naturally when the source or room dimensions are modified.",
        },
      ],
    },
    {
      num: "7",
      heading: "Reverb — Feedback Delay Network",
      content: [
        {
          type: "paragraph",
          text: "After the early reflections, the sound continues bouncing until it dies out — this is the reverb tail. True Position uses a Feedback Delay Network (FDN) with 4 diffusion channels and 4 cascaded stages. The delay times are set based on the maximum reflection distance, and the feedback gain is derived from the user-specified RT60 decay time using the standard formula: gain = 10^(-3 × delay / (RT60 × sampleRate)).",
        },
        {
          type: "paragraph",
          text: "Each FDN channel feeds back into itself through high-pass and low-pass filters, simulating the frequency-dependent absorption of real room surfaces — high frequencies decay faster than low frequencies. The user controls this via the Lowcut and Highcut knobs, which set the corner frequencies of these filters.",
        },
        {
          type: "code",
          language: "cpp",
          caption:
            "Listing 7. The reverb engine processes 4 diffusion channels per sample.",
          code: `double Reverb::process(double in) {
    Array input;
    for (int i = 0; i < diffuseCount; i++)
        input[i] = in;          // feed all 4 channels

    input = bsReverb.process(input);  // FDN with mixing matrix

    double out = 0.0;
    for (int i = 0; i < diffuseCount; i++)
        out += input[i] / (double)diffuseCount / 4.0;
    return out;
}`,
        },
      ],
    },
    {
      num: "8",
      heading: "The Complete Signal Path",
      content: [
        {
          type: "paragraph",
          text: "Putting it all together, the RoomSimulation processes each mono input sample through three parallel paths that are summed to produce each stereo output channel:",
        },
        {
          type: "list",
          items: [
            "Direct path: mono → PositionSimulator (ITD + acoustic shadow) → Dry Gain → output",
            "Early reflections: mono → N × PositionSimulator (one per mirror-image source) → Wet Gain → Low-cut / High-cut EQ → output",
            "Reverb tail: mono → FDN Reverb → Reverb Gain → output",
          ],
        },
        {
          type: "paragraph",
          text: "The Dry, Wet, and Reverb knobs control the relative level of each path. Because all three paths use the same smooth-interpolation infrastructure from SignalProcessor, any knob change — or any source movement — transitions cleanly without clicks, pops, or zipper noise.",
        },
        {
          type: "paragraph",
          text: "The Delay processor deserves special mention: it uses a CircularList (ring buffer) with linear interpolation between adjacent samples for fractional delays. This is critical because the distance from source to ear rarely maps to an exact integer number of samples. Linear interpolation gives approximately -6 dB of aliasing rejection at Nyquist, which is sufficient for delay lines where the content is already band-limited by the source signal.",
        },
        {
          type: "code",
          language: "cpp",
          caption:
            "Listing 8. Fractional delay read with linear interpolation.",
          code: `double Delay::read(double delay) {
    double index1 = floor(delay - 1);
    double index2 = floor(delay);
    double ratio  = 1 - (delay - index1);
    double sample1 = delayBuffer[int(index1)];
    double sample2 = delayBuffer[int(index2)];
    return sample1 * ratio + sample2 * (1 - ratio);
}`,
        },
      ],
    },
    {
      num: "9",
      heading: "Usage & Download",
      content: [
        {
          type: "paragraph",
          text: "True Position is available as a free VST3 plugin. Load it on any mono track (or a stereo track with identical L/R content) in your DAW. The 3D room visualisation lets you drag the sound source in real time. The six knobs — Dry, Wet, Reverb, Decay, Lowcut, Highcut — provide intuitive control over the spatial character.",
        },
        {
          type: "list",
          items: [
            "Source code: https://github.com/kpnn0100/TruePosition",
            "DSP library: https://github.com/kpnn0100/DigitalSignalProcessing",
            "Download VST3: https://github.com/kpnn0100/TruePosition/releases/tag/v1.0",
          ],
        },
        {
          type: "paragraph",
          text: "The full source is open under the MIT licence. The DSP library (Gyrus Space DSP) is a standalone project and can be integrated into any C++ audio application — it has no external dependencies beyond the standard library.",
        },
      ],
    },
  ],
};

export default item;
